


from fastai.vision.all import *
from fastai.text.all import *
from datasets import Dataset
from captcha.image import ImageCaptcha
import random
import string


from src.utils import *
from src.metrics import *








# 2. Create a fake CAPTCHA dataset
def create_captcha_dataset(size=100):
    generator = ImageCaptcha(width=160, height=60)
    data = []
    for _ in range(size):
        label = ''.join(random.choices(string.ascii_uppercase + string.digits, k=5))
        img = generator.generate_image(label)
        data.append({'image': img, 'label': label})  # Using our custom class
    return Dataset.from_list(data)




# 3. Generate the dataset
ds = create_captcha_dataset(1000)


show_image(ds[0]['image'],title=ds[0]['label'],figsize=(3,5))








class CaptchaStr(str):
    def show(self, ctx=None, **kwargs):
        return show_title(self, ctx=ctx)

class TokenizeLabel(Transform):
    vocab = list(string.ascii_uppercase + string.digits)
    def __init__(self):
        self.stoi = {v: k for k, v in enumerate(self.vocab)}

    def encodes(self, x: str):
        return TensorText(tensor([self.stoi[c] for c in x]))

    def decodes(self, x: TensorText):
        indices = x.detach().cpu().flatten().tolist()
        return CaptchaStr(''.join(self.vocab[int(i)] for i in indices))



dblock = DataBlock(
    blocks=(ImageBlock, TransformBlock(type_tfms=TokenizeLabel())),
    get_x=lambda o: o['image'],
    get_y=lambda o: o['label'],  # Already a CaptchaLabel instance
    splitter=RandomSplitter(),
    item_tfms=None,
    batch_tfms=[Normalize()]
)

# 7. Create DataLoaders
dls = dblock.dataloaders(ds, bs=16)


dls.show_batch()






# 7. Improved CNN Backbone
class CNNBackbone(nn.Module):
    def __init__(self):
        super().__init__()
        # First conv block (input: 3x60x160)
        self.conv_block1 = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2)  # 60x160 -> 30x80
        )
        # Second conv block
        self.conv_block2 = nn.Sequential(
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2)  # 30x80 -> 15x40
        )
        # Third conv block
        self.conv_block3 = nn.Sequential(
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),  # Added an extra conv layer
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=(2,1), stride=(2,1))  # 15x40 -> 7x40
        )
        # Fourth conv block
        self.conv_block4 = nn.Sequential(
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),  # Added an extra conv layer
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Dropout2d(0.2),
            nn.MaxPool2d(kernel_size=(2,1), stride=(2,1))  # 7x40 -> 3x40
        )
        # Reduce height to 1, keep width
        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 40))  # Force output width to be 40

    def forward(self, x):
        x = self.conv_block1(x)
        x = self.conv_block2(x)
        x = self.conv_block3(x)
        x = self.conv_block4(x)
        x = self.adaptive_pool(x)
        return x


class CRNN(nn.Module):
    def __init__(self, num_chars):
        super().__init__()
        self.cnn = CNNBackbone()
        # CNN output: [bs, 512, 1, 40]
        lstm_input_size = 512
        hidden_size = 256
        self.num_chars = num_chars

        # Bidirectional LSTM layers
        self.lstm = nn.LSTM(
            lstm_input_size,
            hidden_size,
            num_layers=2,
            bidirectional=True,
            batch_first=False,
            dropout=0.2
        )

        # Initialize LSTM parameters with better values
        for name, param in self.lstm.named_parameters():
            if 'weight_ih' in name:
                nn.init.xavier_uniform_(param)
            elif 'weight_hh' in name:
                nn.init.orthogonal_(param)
            if 'bias' in name:
                nn.init.zeros_(param)
                # Set forget gate bias to 1 (helps with vanishing gradients)
                n = param.size(0)
                param.data[n//4:n//2].fill_(1.0)

        # Output layer
        self.fc = nn.Linear(hidden_size * 2, num_chars + 1)  # +1 for blank

        # Initialize output layer with better values
        nn.init.xavier_uniform_(self.fc.weight)
        nn.init.zeros_(self.fc.bias)

        # CRITICAL: Set bias against blank prediction
        # This helps prevent the "blank collapse" problem
        with torch.no_grad():
            self.fc.bias[num_chars] = -2.0  # Strong negative bias for blank
            # Give a slight positive bias to actual characters
            for i in range(num_chars):
                self.fc.bias[i] = 0.5  # Small positive bias for real characters

    def forward(self, images):
        # Extract CNN features
        features = self.cnn(images)  # [bs, 512, 1, 40]
        bs, C, H, W_seq = features.size()
        assert H == 1, "CNN output height must be 1"

        # Reshape for LSTM: [seq_len, batch_size, features]
        features = features.squeeze(2)      # [bs, 512, 40]
        features = features.permute(2, 0, 1)  # [40, bs, 512]

        # Pass through LSTM
        lstm_out, _ = self.lstm(features)  # [40, bs, 512]

        # Pass through final linear layer
        logits = self.fc(lstm_out)  # [40, bs, num_chars+1]

        # Apply log softmax for CTC loss
        log_probs = F.log_softmax(logits, dim=2)

        # Debug prints - uncomment to see activation distributions
        # print(f"Logits min: {logits.min().item()}, max: {logits.max().item()}, mean: {logits.mean().item()}")
        # print(f"Log_probs min: {log_probs.min().item()}, max: {log_probs.max().item()}, mean: {log_probs.mean().item()}")

        return log_probs








import torch
import torch.nn as nn

class SimpleCTCLoss(nn.Module):
    def __init__(self, blank_token=0, pad_token=-1):
        super().__init__()
        self.blank_token = blank_token
        self.pad_token = pad_token
        self.ctc_loss = nn.CTCLoss(blank=blank_token, reduction='mean', zero_infinity=True)

    def forward(self, log_probs, targets):
        """
        log_probs: (T, N, C) - output from model after log_softmax
        targets: (N, S) - padded with pad_token (-1)
        """
        N = targets.size(0)
        T = log_probs.size(0)

        # Remove pad_token (-1) for each target sequence
        target_lengths = (targets != self.pad_token).sum(dim=1)
        targets_flat = torch.cat([t[t != self.pad_token] for t in targets])

        # Input lengths = full length for all samples
        input_lengths = torch.full((N,), T, dtype=torch.long, device=log_probs.device)

        return self.ctc_loss(log_probs, targets_flat, input_lengths, target_lengths)






model = CRNN(len(dls.vocab))
loss_func = SimpleCTCLoss(blank_token = 0)

def split_params(model):
    return [
        params(model.cnn),         # CNN layers - lower learning rate
        params(model.lstm),        # LSTM layers - medium learning rate
        params(model.fc)           # Final layer - higher learning rate
    ]


learn = Learner(
        dls,
        model,
        loss_func=loss_func,
        splitter=split_params,
        metrics=[CTCAccuracy(CTCDecoder(dls.vocab))],
        wd=1e-3  # Reduced weight decay
)


learn.fit_one_cycle(10, 1e-3)



